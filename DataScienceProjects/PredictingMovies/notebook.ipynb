{"cells":[{"source":"![dvd_image](dvd_image.jpg)\n\nA DVD rental company needs your help! They want to figure out how many days a customer will rent a DVD for based on some features and has approached you for help. They want you to try out some regression models which will help predict the number of days a customer will rent a DVD for. The company wants a model which yeilds a MSE of 3 or less on a test set. The model you make will help the company become more efficient inventory planning.\n\nThe data they provided is in the csv file `rental_info.csv`. It has the following features:\n- `\"rental_date\"`: The date (and time) the customer rents the DVD.\n- `\"return_date\"`: The date (and time) the customer returns the DVD.\n- `\"amount\"`: The amount paid by the customer for renting the DVD.\n- `\"amount_2\"`: The square of `\"amount\"`.\n- `\"rental_rate\"`: The rate at which the DVD is rented for.\n- `\"rental_rate_2\"`: The square of `\"rental_rate\"`.\n- `\"release_year\"`: The year the movie being rented was released.\n- `\"length\"`: Lenght of the movie being rented, in minuites.\n- `\"length_2\"`: The square of `\"length\"`.\n- `\"replacement_cost\"`: The amount it will cost the company to replace the DVD.\n- `\"special_features\"`: Any special features, for example trailers/deleted scenes that the DVD also has.\n- `\"NC-17\"`, `\"PG\"`, `\"PG-13\"`, `\"R\"`: These columns are dummy variables of the rating of the movie. It takes the value 1 if the move is rated as the column name and 0 otherwise. For your convinience, the reference dummy has already been dropped.","metadata":{},"id":"b4ae5707-109f-4cd6-8168-88cac0179d6b","cell_type":"markdown"},{"source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\n# Import any additional modules and start coding below","metadata":{"executionCancelledAt":null,"executionTime":11,"lastExecutedAt":1771036967753,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\n# Import any additional modules and start coding below","lastExecutedByKernel":"09f91413-f56c-46c5-91b2-dba62c78966d"},"id":"a7ede566-910a-445c-b11a-68d192ac8506","cell_type":"code","execution_count":91,"outputs":[]},{"source":"#lets open the data and do some exploration\ndf = pd.read_csv('rental_info.csv')\n\nprint(df.info())","metadata":{"executionCancelledAt":null,"executionTime":56,"lastExecutedAt":1771036967809,"lastExecutedByKernel":"09f91413-f56c-46c5-91b2-dba62c78966d","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#lets open the data and do some exploration\ndf = pd.read_csv('rental_info.csv')\n\nprint(df.info())","outputsMetadata":{"0":{"height":500,"type":"stream"}}},"cell_type":"code","id":"1041b133-5218-4fa9-8bd0-deb4933517ba","outputs":[{"output_type":"stream","name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 15861 entries, 0 to 15860\nData columns (total 15 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   rental_date       15861 non-null  object \n 1   return_date       15861 non-null  object \n 2   amount            15861 non-null  float64\n 3   release_year      15861 non-null  float64\n 4   rental_rate       15861 non-null  float64\n 5   length            15861 non-null  float64\n 6   replacement_cost  15861 non-null  float64\n 7   special_features  15861 non-null  object \n 8   NC-17             15861 non-null  int64  \n 9   PG                15861 non-null  int64  \n 10  PG-13             15861 non-null  int64  \n 11  R                 15861 non-null  int64  \n 12  amount_2          15861 non-null  float64\n 13  length_2          15861 non-null  float64\n 14  rental_rate_2     15861 non-null  float64\ndtypes: float64(8), int64(4), object(3)\nmemory usage: 1.8+ MB\nNone\n"}],"execution_count":92},{"source":"#lets create a feature called rental_length_days with return date and rental date, append it ot pandas\n\n#set both cols to datetime so pandas understands its a date object\n\ndf['rental_date'] = pd.to_datetime(df['rental_date'])\ndf['return_date'] = pd.to_datetime(df['return_date'])\n\n#now we can do some math on it\n\ndf['rental_length_days'] = (df['return_date'] - df['rental_date']).dt.days\n\nprint(df['rental_length_days'].head(3))","metadata":{"executionCancelledAt":null,"executionTime":60,"lastExecutedAt":1771036967869,"lastExecutedByKernel":"09f91413-f56c-46c5-91b2-dba62c78966d","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#lets create a feature called rental_length_days with return date and rental date, append it ot pandas\n\n#set both cols to datetime so pandas understands its a date object\n\ndf['rental_date'] = pd.to_datetime(df['rental_date'])\ndf['return_date'] = pd.to_datetime(df['return_date'])\n\n#now we can do some math on it\n\ndf['rental_length_days'] = (df['return_date'] - df['rental_date']).dt.days\n\nprint(df['rental_length_days'].head(3))","outputsMetadata":{"0":{"height":101,"type":"stream"}}},"cell_type":"code","id":"7bea6395-e0d2-46fc-887a-793f5c490005","outputs":[{"output_type":"stream","name":"stdout","text":"0    3\n1    2\n2    7\nName: rental_length_days, dtype: int64\n"}],"execution_count":93},{"source":"df['deleted_scenes'] = np.where(df['special_features'].str.contains(\"Deleted Scenes\"),1,0)\n\ndf['behind_the_scenes'] = np.where(df['special_features'].str.contains(\"Behind the Scenes\"),1,0)","metadata":{"executionCancelledAt":null,"executionTime":59,"lastExecutedAt":1771036967928,"lastExecutedByKernel":"09f91413-f56c-46c5-91b2-dba62c78966d","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"df['deleted_scenes'] = np.where(df['special_features'].str.contains(\"Deleted Scenes\"),1,0)\n\ndf['behind_the_scenes'] = np.where(df['special_features'].str.contains(\"Behind the Scenes\"),1,0)"},"cell_type":"code","id":"3a3e2a8f-46f0-4343-a922-ae192f6639e5","outputs":[],"execution_count":94},{"source":"X = df.drop(columns=['rental_date', 'return_date', 'special_features', 'rental_length_days'])\ny = df['rental_length_days']","metadata":{"executionCancelledAt":null,"executionTime":59,"lastExecutedAt":1771036967988,"lastExecutedByKernel":"09f91413-f56c-46c5-91b2-dba62c78966d","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"X = df.drop(columns=['rental_date', 'return_date', 'special_features', 'rental_length_days'])\ny = df['rental_length_days']"},"cell_type":"code","id":"f36897c0-b19c-49d7-8058-dba4f7fc788b","outputs":[],"execution_count":95},{"source":"#train test\nX_train, X_Test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 9)","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1771036968038,"lastExecutedByKernel":"09f91413-f56c-46c5-91b2-dba62c78966d","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#train test\nX_train, X_Test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 9)"},"cell_type":"code","id":"7741137a-4aec-4abd-98b9-83878c2da0b8","outputs":[],"execution_count":96},{"source":"#lets use Lasso for the love of the game\n\nfrom sklearn.linear_model import Lasso\nlasso = Lasso(alpha=0.1, random_state=9)\nlasso.fit(X_train, y_train)\n\ncoefs = lasso.coef_\nmask = coefs != 0\n\nX_train = X_train.iloc[:, mask]\nX_test = X_Test.iloc[:, mask]","metadata":{"executionCancelledAt":null,"executionTime":276,"lastExecutedAt":1771036968315,"lastExecutedByKernel":"09f91413-f56c-46c5-91b2-dba62c78966d","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#lets use Lasso for the love of the game\n\nfrom sklearn.linear_model import Lasso\nlasso = Lasso(alpha=0.1, random_state=9)\nlasso.fit(X_train, y_train)\n\ncoefs = lasso.coef_\nmask = coefs != 0\n\nX_train = X_train.iloc[:, mask]\nX_test = X_Test.iloc[:, mask]"},"cell_type":"code","id":"b1861080-2541-49d5-9621-35cc072aafda","outputs":[],"execution_count":97},{"source":"#now lets have a good list of models to try and test \n\nimport numpy as np\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\nfrom sklearn.tree import DecisionTreeRegressor\n\"\"\"\n#model params list \nmodel_params = {\n    'Linear Regression': (\n        LinearRegression(),\n        {'fit_intercept': [True, False]}\n    ),\n    \n    'Random Forest': (\n        RandomForestRegressor(random_state=9),\n        {\n            # range(start, stop) creates a list of integers\n            'n_estimators': list(range(50, 200, 10)),  # [50, 60, ..., 190]\n            'max_depth': [None, 10, 20, 30, 40],\n            'min_samples_split': [2, 5, 10],\n            'min_samples_leaf': [1, 2, 4]\n        }\n    ),\n    \n    'Decision Tree': (\n        DecisionTreeRegressor(random_state=9),\n        {\n            'max_depth': [None, 5, 10, 20, 30],\n            'min_samples_leaf': list(range(1, 10)),\n            'max_features': ['sqrt', 'log2', None] \n        }\n    ),\n    \n    'AdaBoost': (\n        AdaBoostRegressor(random_state=9),\n        {\n            'n_estimators': list(range(50, 200, 10)),\n            # np.linspace creates evenly spaced numbers\n            'learning_rate': np.linspace(0.01, 1.0, 20), \n            'loss': ['linear', 'square', 'exponential']\n        }\n    )\n}\n\nbest_models = {}\n\nfor name, (model, params) in model_params.items():\n    print(f\"Running search for {name}...\")\n    \n    rs = RandomizedSearchCV(\n        estimator=model,\n        param_distributions=params,\n        n_iter=20,             \n        cv=5,                  \n        scoring='neg_mean_squared_error',\n        n_jobs=-1,             \n        random_state=9\n    )\n\n    rs.fit(X_train, y_train)\n    \n    best_models[name] = rs.best_estimator_\n    \n    print(f\"  Best Params: {rs.best_params_}\")\n    print(f\"  Best Negative MSE: {rs.best_score_:.4f}\\n\")\n\"\"\"\n","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1771036968369,"lastExecutedByKernel":"09f91413-f56c-46c5-91b2-dba62c78966d","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#now lets have a good list of models to try and test \n\nimport numpy as np\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\nfrom sklearn.tree import DecisionTreeRegressor\n\"\"\"\n#model params list \nmodel_params = {\n    'Linear Regression': (\n        LinearRegression(),\n        {'fit_intercept': [True, False]}\n    ),\n    \n    'Random Forest': (\n        RandomForestRegressor(random_state=9),\n        {\n            # range(start, stop) creates a list of integers\n            'n_estimators': list(range(50, 200, 10)),  # [50, 60, ..., 190]\n            'max_depth': [None, 10, 20, 30, 40],\n            'min_samples_split': [2, 5, 10],\n            'min_samples_leaf': [1, 2, 4]\n        }\n    ),\n    \n    'Decision Tree': (\n        DecisionTreeRegressor(random_state=9),\n        {\n            'max_depth': [None, 5, 10, 20, 30],\n            'min_samples_leaf': list(range(1, 10)),\n            'max_features': ['sqrt', 'log2', None] \n        }\n    ),\n    \n    'AdaBoost': (\n        AdaBoostRegressor(random_state=9),\n        {\n            'n_estimators': list(range(50, 200, 10)),\n            # np.linspace creates evenly spaced numbers\n            'learning_rate': np.linspace(0.01, 1.0, 20), \n            'loss': ['linear', 'square', 'exponential']\n        }\n    )\n}\n\nbest_models = {}\n\nfor name, (model, params) in model_params.items():\n    print(f\"Running search for {name}...\")\n    \n    rs = RandomizedSearchCV(\n        estimator=model,\n        param_distributions=params,\n        n_iter=20,             \n        cv=5,                  \n        scoring='neg_mean_squared_error',\n        n_jobs=-1,             \n        random_state=9\n    )\n\n    rs.fit(X_train, y_train)\n    \n    best_models[name] = rs.best_estimator_\n    \n    print(f\"  Best Params: {rs.best_params_}\")\n    print(f\"  Best Negative MSE: {rs.best_score_:.4f}\\n\")\n\"\"\"\n","outputsMetadata":{"0":{"height":353,"type":"stream"}}},"cell_type":"code","id":"6da4613d-7f07-49db-bf55-bdc0028c0619","outputs":[{"output_type":"execute_result","data":{"text/plain":"'\\n#model params list \\nmodel_params = {\\n    \\'Linear Regression\\': (\\n        LinearRegression(),\\n        {\\'fit_intercept\\': [True, False]}\\n    ),\\n    \\n    \\'Random Forest\\': (\\n        RandomForestRegressor(random_state=9),\\n        {\\n            # range(start, stop) creates a list of integers\\n            \\'n_estimators\\': list(range(50, 200, 10)),  # [50, 60, ..., 190]\\n            \\'max_depth\\': [None, 10, 20, 30, 40],\\n            \\'min_samples_split\\': [2, 5, 10],\\n            \\'min_samples_leaf\\': [1, 2, 4]\\n        }\\n    ),\\n    \\n    \\'Decision Tree\\': (\\n        DecisionTreeRegressor(random_state=9),\\n        {\\n            \\'max_depth\\': [None, 5, 10, 20, 30],\\n            \\'min_samples_leaf\\': list(range(1, 10)),\\n            \\'max_features\\': [\\'sqrt\\', \\'log2\\', None] \\n        }\\n    ),\\n    \\n    \\'AdaBoost\\': (\\n        AdaBoostRegressor(random_state=9),\\n        {\\n            \\'n_estimators\\': list(range(50, 200, 10)),\\n            # np.linspace creates evenly spaced numbers\\n            \\'learning_rate\\': np.linspace(0.01, 1.0, 20), \\n            \\'loss\\': [\\'linear\\', \\'square\\', \\'exponential\\']\\n        }\\n    )\\n}\\n\\nbest_models = {}\\n\\nfor name, (model, params) in model_params.items():\\n    print(f\"Running search for {name}...\")\\n    \\n    rs = RandomizedSearchCV(\\n        estimator=model,\\n        param_distributions=params,\\n        n_iter=20,             \\n        cv=5,                  \\n        scoring=\\'neg_mean_squared_error\\',\\n        n_jobs=-1,             \\n        random_state=9\\n    )\\n\\n    rs.fit(X_train, y_train)\\n    \\n    best_models[name] = rs.best_estimator_\\n    \\n    print(f\"  Best Params: {rs.best_params_}\")\\n    print(f\"  Best Negative MSE: {rs.best_score_:.4f}\\n\")\\n'"},"metadata":{},"execution_count":98}],"execution_count":98},{"source":"#got best model params\n\n#RandomForest\n#{'n_estimators': 140, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 30}\n\nbest_model = RandomForestRegressor(\n    n_estimators=140,\n    min_samples_split=2,\n    min_samples_leaf=1,\n    max_depth=30\n).fit(X_train, y_train)\n\n\ny_pred = best_model.predict(X_test)","metadata":{"executionCancelledAt":null,"executionTime":1636,"lastExecutedAt":1771036970005,"lastExecutedByKernel":"09f91413-f56c-46c5-91b2-dba62c78966d","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#got best model params\n\n#RandomForest\n#{'n_estimators': 140, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 30}\n\nbest_model = RandomForestRegressor(\n    n_estimators=140,\n    min_samples_split=2,\n    min_samples_leaf=1,\n    max_depth=30\n).fit(X_train, y_train)\n\n\ny_pred = best_model.predict(X_test)"},"cell_type":"code","id":"a5cb1a3e-e04b-45e8-88d3-61dca1802caf","outputs":[],"execution_count":99},{"source":"#now we get MSE\n\nbest_mse = mean_squared_error(y_test, y_pred)\n\nprint(best_mse)","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1771036970058,"lastExecutedByKernel":"09f91413-f56c-46c5-91b2-dba62c78966d","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#now we get MSE\n\nbest_mse = mean_squared_error(y_test, y_pred)\n\nprint(best_mse)","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"aae8e9be-4e8c-4a2c-ae2d-f73bdd7efa67","outputs":[{"output_type":"stream","name":"stdout","text":"2.1123024962147596\n"}],"execution_count":100}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}